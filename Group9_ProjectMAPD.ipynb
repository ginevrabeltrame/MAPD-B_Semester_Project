{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5debf4-0c3d-4124-a9ba-c9ebf3bc9017",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"font-size: 20px;\">\n",
    "        Final project for the <strong style=\"font-size: 26px;\"> MAPD-B </strong> course<br>\n",
    "        <strong style=\"font-size: 35px; display: block; margin-top: 20px;\">4 - Batch analysis of cosmic rays using Drift Tubes detectors</strong>\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<hr style=\"border: 1px solid #000;\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; align-items: center;\">\n",
    "    <div style=\"flex: 1; text-align: center;\">\n",
    "        <img src=\"unipd_template.png\" alt=\"Unipd template\" width=\"400\" style=\"margin-right: 100px; margin-left: 100px;\">\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"pod_template.png\" alt=\"PoD template\" width=\"250\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"border: 1px solid #000;\">\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-between; text-align: left; \">\n",
    "    <div style=\"flex: 1;\">\n",
    "        <!-- Questo spazio può essere vuoto se non serve altro qui -->\n",
    "    </div>\n",
    "    <div style=\"flex: 1; font-size: 16px;\">\n",
    "        <p><strong>Degree:</strong> Physics of Data</p>\n",
    "        <p><strong>Course:</strong> Management and Analysis of Physics Dataset (mod.B) </p>\n",
    "        <p><strong>Year:</strong> 2023-2024</p>\n",
    "        <p><strong>Teacher:</strong> prof. Jacopo Pazzini </p>\n",
    "        <table style=\"margin: 0 auto; border-collapse: collapse; width: 80%; font-size: 15px;\">\n",
    "            <thead>\n",
    "                <tr>\n",
    "                    <th colspan=\"3\" style=\"border: none; padding: 2px; text-align: center; font-weight: bold; font-size: 18px\">Group 9 students</th>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <th style=\"border: none; padding: 6px;\">Name</th>\n",
    "                    <th style=\"border: none; padding: 6px;\">ID</th>\n",
    "                    <th style=\"border: none; padding: 2px;\">Email</th>\n",
    "                </tr>\n",
    "            </thead>\n",
    "            <tbody>\n",
    "                <tr>\n",
    "                    <td style=\"border: none; padding: 6px;\">Ginevra Beltrame</td>\n",
    "                    <td style=\"border: none; padding: 6px;\">2130668</td>\n",
    "                    <td style=\"border: none; padding: 2px;\">ginevra.beltrame@studenti.unipd.it</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: none; padding: 6px;\">Emanuele Coradin</td>\n",
    "                    <td style=\"border: none; padding: 6px;\">2124732</td>\n",
    "                    <td style=\"border: none; padding: 2px;\">emanuele.coradin@studenti.unipd.it</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: none; padding: 6px;\">Arina Ponomareva</td>\n",
    "                    <td style=\"border: none; padding: 6px;\">2106897</td>\n",
    "                    <td style=\"border: none; padding: 2px;\">arina.ponomareva@studenti.unipd.it</td>\n",
    "                </tr>\n",
    "                <tr>\n",
    "                    <td style=\"border: none; padding: 6px;\">Margarita Shnaider</td>\n",
    "                    <td style=\"border: none; padding: 6px;\">2107523</td>\n",
    "                    <td style=\"border: none; padding: 2px;\">margarita.shnaider@studenti.unipd.it</td>\n",
    "                </tr>\n",
    "            </tbody>\n",
    "        </table>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f3574-2ee9-4a7d-9229-dc28f5574f3f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"font-size: 20px;\">\n",
    "        <strong style=\"font-size: 35px; display: block; margin-top: 20px;\">Part 1 - Data Analysis</strong>\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca91623-0e64-496f-996a-d80f7565d0c7",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0181b508-0fa9-4586-9d37-1e5f2aee81d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f287df13c50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import struct, time\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import SSHCluster\n",
    "from dask.distributed import LocalCluster # local cluster setup (temporary)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import dask.dataframe as dd \n",
    "import dask.array as da\n",
    "from dask.delayed import delayed\n",
    "import dask.bag as db\n",
    "\n",
    "import graphviz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "dask.config.set({'dataframe.query-planning':True}) # activates an SQL-based efficient optimization of the queries in dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24db87-7d7d-4a02-8741-0555a5f1cb4f",
   "metadata": {},
   "source": [
    "#### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bcc7d8-7fd1-40a1-b32e-d187dcf20367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful global variables\n",
    "\n",
    "MAX_HIT_ORB  = 20\n",
    "MIN_HIT_ORB = 6\n",
    "MIN_HITS_PER_CHAMBER = 3\n",
    "\n",
    "hreg = HuberRegressor(max_iter=30, epsilon=1.05, tol=1e-4)\n",
    "CELL_WIDTH  = 42\n",
    "CELL_HEIGHT = 13\n",
    "\n",
    "n_partitions = 48\n",
    "\n",
    "time_offset_by_chamber = {\n",
    "    0: 95.0 - 1.1, # Ch 0\n",
    "    1: 95.0 + 6.4, # Ch 1\n",
    "    2: 95.0 + 0.5, # Ch 2\n",
    "    3: 95.0 - 2.6, # Ch 3\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "V_DRIFT = 53.8e-3 # µm/ns = 10^-3 mm/ns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413361a-6e9a-4347-9bb1-5dd6696a848f",
   "metadata": {},
   "source": [
    "#### Dataframe structure setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b429c6cd-91a9-4eae-98db-6eabac041f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpga_column = np.array([np.zeros(128), np.ones(128)], dtype=np.int32).flatten()\n",
    "tdc_column = np.hstack((np.arange(0, 128), np.arange(0, 128)))\n",
    "chamber_column = np.array([np.zeros(64), np.ones(64), 2*np.ones(64), 3*np.ones(64)], dtype=np.int32).flatten()\n",
    "z_column = np.array([219.8*np.ones(64), 977.3*np.ones(64), 1035.6*np.ones(64), 1819.8*np.ones(64)]).flatten()\n",
    "\n",
    "dict_bricks = {\n",
    "    'FPGA' : fpga_column,\n",
    "    'TDC_CHANNEL': tdc_column,\n",
    "    'Chamber': chamber_column,\n",
    "    'x' : np.zeros(256),\n",
    "    'y' : np.zeros(256),\n",
    "    'z' : z_column,\n",
    "}\n",
    "\n",
    "df_bricks = pd.DataFrame(dict_bricks)\n",
    "\n",
    "z_list = 13*np.array([7/2, 3/2, 5/2, 1/2])\n",
    "indices = df_bricks['TDC_CHANNEL'] % 4\n",
    "z_addition = indices.map(lambda idx: z_list[idx])\n",
    "\n",
    "df_bricks['z'] = df_bricks['z'] + z_addition\n",
    "df_bricks.loc[df_bricks['Chamber'].isin([0, 2, 3]), 'x'] = df_bricks['x'] + 21 * ((df_bricks['TDC_CHANNEL']%64) // 2) + 21\n",
    "df_bricks.loc[df_bricks['Chamber'].isin([1]), 'y'] = df_bricks['y'] + 21 * ((df_bricks['TDC_CHANNEL']%64) // 2)\n",
    "\n",
    "#df_bricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352d6ed2-03df-4c55-a115-996b4ab81607",
   "metadata": {},
   "source": [
    "#### Processing functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767e45d3-2390-47b7-a4a4-bf7e2166b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "def read_file(filename):\n",
    "    client_kwargs = {\n",
    "        'endpoint_url': 'https://cloud-areapd.pd.infn.it:5210',\n",
    "        'verify': False\n",
    "    }\n",
    "    \n",
    "    # Read bytes from the specified S3 bucket with the given credentials and client configurations\n",
    "    sample, blocks = dask.bytes.read_bytes(\n",
    "        filename,\n",
    "        key='f74a337e5aeb4b388d0284044a87aa38',\n",
    "        secret='e8b5fac442dc426089f9843bcc78556a',\n",
    "        client_kwargs=client_kwargs\n",
    "    )\n",
    "    df_chuncks = [convert_bytes(block[0]) for block in blocks]\n",
    "    df = dd.from_delayed(df_chuncks)\n",
    "    return df\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "@dask.delayed\n",
    "def convert_bytes(byte_file):\n",
    "    word_size = 8\n",
    "    head_number = 2\n",
    "\n",
    "    # Convert byte file to a numpy array of integers\n",
    "    # obs: 8 byte words can be stored into int64\n",
    "    byte_array = np.frombuffer(byte_file, dtype=np.uint64)\n",
    "    \n",
    "    # Extract fields\n",
    "    head = (byte_array >> 61) & 0x7\n",
    "    fpga = (byte_array >> 58) & 0x7\n",
    "    tdc_chan = (byte_array >> 49) & 0x1FF\n",
    "    orb_cnt = (byte_array >> 17) & 0xFFFFFFFF\n",
    "    bx = (byte_array >> 5) & 0xFFF\n",
    "    tdc_meas = (byte_array >> 0) & 0x1F\n",
    "\n",
    "    mask = (head == head_number)\n",
    "\n",
    "    data = {\n",
    "        'FPGA': fpga[mask],\n",
    "        'TDC_CHANNEL': tdc_chan[mask],\n",
    "        'ORB_CNT': orb_cnt[mask],\n",
    "        'BX': bx[mask],\n",
    "        'TDC_MEAS': tdc_meas[mask]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def assign_chamber(row):\n",
    "    if row['FPGA'] == 0:\n",
    "        if 0 <= row['TDC_CHANNEL'] <= 63:\n",
    "            return 0\n",
    "        elif 64 <= row['TDC_CHANNEL'] <= 127:\n",
    "            return 1\n",
    "    elif row['FPGA'] == 1:\n",
    "        if 0 <= row['TDC_CHANNEL'] <= 63:\n",
    "            return 2\n",
    "        elif 64 <= row['TDC_CHANNEL'] <= 128:\n",
    "            return 3\n",
    "    return -1\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def filter_groups_part1(df):\n",
    "    # Filter with scintillator's information\n",
    "    scintillator_df = df[(df.FPGA == 1) & (df.TDC_CHANNEL == 128)].drop_duplicates(subset='ORB_CNT', keep='first')\n",
    "    scintillator_df['t0'] = 25 * (scintillator_df['BX'] + scintillator_df['TDC_MEAS'] / 30)\n",
    "    scintillator_df = scintillator_df[['ORB_CNT', 't0']]\n",
    "    \n",
    "    # Remove scintillator info from the main DataFrame\n",
    "    df = df[df.TDC_CHANNEL < 128]\n",
    "\n",
    "    df = df.merge(scintillator_df, on='ORB_CNT', how='inner')\n",
    "    return df\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def threshold_analysis(threshold, low_filter, df):\n",
    "    df_grouped = df.groupby('ORB_CNT')['FPGA'].count()\n",
    "    orbits_to_drop = df_grouped[(df_grouped > threshold) | (df_grouped < low_filter)].index\n",
    "    print('orbits to drop: ', len(orbits_to_drop), '/', len(df_grouped.index))\n",
    "\n",
    "    # Set bins to be integers to remove spaces between bins\n",
    "    bins = np.arange(df_grouped.min(), df_grouped.max() + 1, 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    ax.hist(df_grouped, bins=bins, color='lightskyblue', align='mid', edgecolor='royalblue')\n",
    "    ax.set_xlabel('Hits per orbit')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_xlim(0, 75)\n",
    "    ax.axvline(x=threshold, color='r', linestyle='--', linewidth=1)\n",
    "    ax.axvline(x=low_filter, color='firebrick', linestyle='--', linewidth=1)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def filter_groups_part2_a(df):    \n",
    "    # Assign chamber information\n",
    "    df['Chamber'] = df.apply(assign_chamber, axis=1, meta=('Chamber', 'float64'))\n",
    "    \n",
    "    # Add further information\n",
    "    df['relative_time'] = 25 * (df['BX'] + df['TDC_MEAS'] / 30)\n",
    "    df = df.drop(columns=['BX', 'TDC_MEAS'])\n",
    "    \n",
    "    # Calculate relative time by subtracting t0\n",
    "    df['relative_time'] = df['relative_time'] - df['t0']\n",
    "    df = df.drop(columns=['t0'])\n",
    "\n",
    "    # Add time offsets based on the chamber\n",
    "    df['relative_time'] = df['relative_time'] + df['Chamber'].map(time_offset_by_chamber)\n",
    "\n",
    "    # Calculate x_left and x_right positions based on the drift velocity\n",
    "    df['x_left']  = - V_DRIFT*df['relative_time']\n",
    "    df['x_right'] = + V_DRIFT*df['relative_time']\n",
    "    df['z'] = 0\n",
    "\n",
    "    # Drop non-physical positions\n",
    "    df = df[(df.x_left.between(-CELL_WIDTH/2, 0)) & (df.x_right.between(0, CELL_WIDTH/2))]\n",
    "\n",
    "    return df\n",
    "    \n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def filter_groups_part2_b(df):    \n",
    "    # Drop events based on number of hits\n",
    "   \n",
    "    #Remove hits of chambers with less than MIN_HITS_PER_CHAMBER hits\n",
    "    grouped = df.groupby(['ORB_CNT', 'Chamber']).filter(lambda x: len(x) >= MIN_HITS_PER_CHAMBER)\n",
    "    df = df.loc[df.ORB_CNT.isin(grouped.ORB_CNT)]\n",
    "\n",
    "    # Remove events based on total number of hits\n",
    "    grouped = df.groupby('ORB_CNT').filter(lambda x: MIN_HIT_ORB <= len(x) <= MAX_HIT_ORB)\n",
    "    df = df.loc[df.ORB_CNT.isin(grouped.ORB_CNT)]\n",
    "\n",
    "    # Create a mask for Chamber 1\n",
    "    mask_chamber_1 = (df['Chamber'] == 1)\n",
    "    \n",
    "    # For Chambers other than 1, adjust x_left and x_right positions\n",
    "    df.loc[~mask_chamber_1, 'x_left']  = df.loc[~mask_chamber_1, 'x_left']  + df_bricks.loc[(df.loc[~mask_chamber_1, 'Chamber']//2)*128 + df.loc[~mask_chamber_1, 'TDC_CHANNEL'], 'x'].values\n",
    "    df.loc[~mask_chamber_1, 'x_right'] = df.loc[~mask_chamber_1, 'x_right'] + df_bricks.loc[(df.loc[~mask_chamber_1, 'Chamber']//2)*128 + df.loc[~mask_chamber_1, 'TDC_CHANNEL'], 'x'].values\n",
    "    \n",
    "    # For Chamber 1, adjust x_left and x_right positions\n",
    "    df.loc[mask_chamber_1, 'x_left']  = df.loc[mask_chamber_1, 'x_left']  + df_bricks.loc[(df.loc[mask_chamber_1, 'Chamber']//2)*128 + df.loc[mask_chamber_1, 'TDC_CHANNEL'], 'y'].values\n",
    "    df.loc[mask_chamber_1, 'x_right'] = df.loc[mask_chamber_1, 'x_right'] + df_bricks.loc[(df.loc[mask_chamber_1, 'Chamber']//2)*128 + df.loc[mask_chamber_1, 'TDC_CHANNEL'], 'y'].values\n",
    "    \n",
    "    # Adjust z positions based on the bricks information\n",
    "    df['z'] = df['z'] + df_bricks.loc[(df['Chamber']//2)*128 + df['TDC_CHANNEL'], 'z'].values\n",
    "\n",
    "    return df\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def fit_tracks_vectorized(group):\n",
    "    \n",
    "    x_left = group['x_left'].values\n",
    "    x_right = group['x_right'].values\n",
    "    z = group['z'].values\n",
    "    chamber = group['Chamber'].values[0]\n",
    "    orb_cnt = group['ORB_CNT'].values[0]\n",
    "\n",
    "    # Group the data by 'z' to ensure we are considering all combinations of points with the same z\n",
    "    grouped_by_z = group.groupby('z')\n",
    "\n",
    "    # List to store all combinations of x-values for different z values\n",
    "    x_combinations = []\n",
    "    list_stacks = []\n",
    "\n",
    "    # Loop through each unique z value and get combinations of x_left and x_right\n",
    "    for z_value, sub_group in grouped_by_z:\n",
    "        x_left_sub = sub_group['x_left'].values\n",
    "        x_right_sub = sub_group['x_right'].values\n",
    "\n",
    "        # Stack left and right x-values for this z\n",
    "        stack = np.column_stack((x_left_sub, x_right_sub)).flatten()\n",
    "        list_stacks.append(stack)\n",
    "\n",
    "    # Use numpy.meshgrid to create a multi-dimensional grid\n",
    "    meshgrid_result = np.meshgrid(*list_stacks, indexing='ij')\n",
    "\n",
    "    # Reshape and flatten the resulting arrays into a list of combinations\n",
    "    x_combinations = np.array([grid.ravel() for grid in meshgrid_result]).T\n",
    "    x_combinations_all = np.vstack(x_combinations)\n",
    "    z_rows = np.sort(np.unique(group['z']))\n",
    "\n",
    "    # Matrix for least squares: z-values and a column of ones for the intercept term\n",
    "    A = np.vstack((z_rows, np.ones(len(z_rows)))).T\n",
    "\n",
    "    # Perform least-squares fit on all combinations at once\n",
    "    coeffs, residuals, _, _ = np.linalg.lstsq(A, x_combinations_all.T, rcond=None)\n",
    "\n",
    "    # Compute chi-squared/ndof for all combinations\n",
    "    chi_squared_ndof = residuals / (len(z_rows) - 2)  # Adjust degrees of freedom\n",
    "    \n",
    "    if chi_squared_ndof.size == 0:\n",
    "        #print(f\"Empty chi_squared_ndof for Chamber {chamber}, ORB_CNT {orb_cnt}\")\n",
    "        return None\n",
    "\n",
    "    # Find the combination with the least chi-squared/ndof\n",
    "    best_fit_idx = np.argmin(chi_squared_ndof)\n",
    "    best_x = x_combinations_all[best_fit_idx]\n",
    "\n",
    "    # Extract the best coefficients and intercept for the best fit\n",
    "    reg_coef = coeffs[0][best_fit_idx]\n",
    "    reg_intercept = coeffs[1][best_fit_idx]\n",
    "\n",
    "    # Return a DataFrame with the fit results\n",
    "    new_row = pd.DataFrame({\n",
    "        'Chamber_': [chamber],\n",
    "        'ORB_CNT_': [orb_cnt],\n",
    "        'x_values': [best_x],\n",
    "        'z_values': [z_rows],\n",
    "        'Reg_Coefficient': [reg_coef],\n",
    "        'Reg_Intercept': [reg_intercept],\n",
    "        'Chi_Squared_NDOF': [chi_squared_ndof[best_fit_idx]]\n",
    "    })\n",
    "\n",
    "    return new_row\n",
    "     \n",
    "#___________________________________________________________________________________________________________________________________\n",
    "\n",
    "def fit_global_tracks(group):\n",
    "    orb_cnt = group['ORB_CNT'].values[0]\n",
    "    group = group[group['Chamber'].isin([0, 2, 3])]\n",
    "    \n",
    "    if group.empty or len(group) < 2:  # Need at least 2 points for a fit\n",
    "        new_row =  pd.DataFrame({\n",
    "            'ORB_CNT_': [orb_cnt],\n",
    "            'Reg_Coefficient': [np.nan],\n",
    "            'Reg_Intercept':   [np.nan],\n",
    "            'Chi_Squared_NDOF': [np.nan]\n",
    "        })\n",
    "        return new_row\n",
    "        \n",
    "    x  = np.concatenate(group['x_values'].values)\n",
    "    z  = np.concatenate(group['z_values'].values).T\n",
    "    \n",
    "    try:\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\", ConvergenceWarning)\n",
    "            \n",
    "            A = np.vstack((z, np.ones(len(z)))).T\n",
    "\n",
    "            coeffs, residual, _, _ = np.linalg.lstsq(A, x.T, rcond=None)\n",
    "            global_slope = coeffs[0]\n",
    "            global_intercept = coeffs[1]\n",
    "            \n",
    "            chi_squared_ndof = residual / (len(z) - 2)\n",
    "            \n",
    "            if chi_squared_ndof.size == 0:\n",
    "                return None\n",
    "    \n",
    "            new_row = pd.DataFrame({\n",
    "                'ORB_CNT_': [orb_cnt],\n",
    "                'Reg_Coefficient': [global_slope],\n",
    "                'Reg_Intercept': [global_intercept],\n",
    "                'Chi_Squared_NDOF': [chi_squared_ndof[0]]\n",
    "            })\n",
    "    \n",
    "            # Check if any ConvergenceWarnings were raised\n",
    "            if any(issubclass(warning.category, ConvergenceWarning) for warning in w):\n",
    "                raise RuntimeError(\"Convergence warning captured: Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html\")\n",
    "    \n",
    "    except (ValueError, RuntimeError) as e:\n",
    "        new_row = pd.DataFrame({\n",
    "            'ORB_CNT_': [orb_cnt],\n",
    "            'Reg_Coefficient': [np.nan],\n",
    "            'Reg_Intercept': [np.nan],\n",
    "            'Chi_Squared_NDOF': [np.nan]\n",
    "        })\n",
    "    return new_row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052f6bd-4a91-4504-98cc-ce7323155044",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plotting functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26e4db3-84f4-4f61-b947-9919a206e8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hit_counts(chambers, df_res, df_bricks):\n",
    "    TDC_counts = df_res[df_res['TDC_CHANNEL'] < 128]\n",
    "    TDC_counts['TDC_unique'] = 128 * TDC_counts['FPGA'] + TDC_counts['TDC_CHANNEL']\n",
    "    TDC_counts = TDC_counts.groupby('TDC_unique').count().iloc[:, [1]].rename(columns={'TDC_CHANNEL': 'Counts'})\n",
    "    \n",
    "    fig, axes = plt.subplots(len(chambers), 1, figsize=(12, 10 * len(chambers) / 3))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Create normalization and colormap\n",
    "    norm = plt.Normalize(np.min(TDC_counts['Counts']), np.max(TDC_counts['Counts']))\n",
    "    cmap = plt.cm.plasma\n",
    "    \n",
    "    # Create ScalarMappable for colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # For the colorbar to have a reference\n",
    "    \n",
    "    for i, chamber in enumerate(chambers):\n",
    "        ax = axes[i]\n",
    "        bricks_data = df_bricks[df_bricks['Chamber'] == chamber]\n",
    "        if chamber == 1:  # using 'y' for scatter plot in chamber 1\n",
    "            ax.scatter(bricks_data['y'], bricks_data['z'], color='red', label='wire', marker='.')\n",
    "            for index, row in bricks_data.iterrows():\n",
    "                # Default color to a neutral one if the index is missing\n",
    "                color = cmap(norm(0))\n",
    "                if index in TDC_counts.index:\n",
    "                    color = cmap(norm(TDC_counts.loc[index, 'Counts']))\n",
    "                rect = patches.Rectangle((row['y'] - CELL_WIDTH / 2, row['z'] - CELL_HEIGHT / 2),\n",
    "                                         CELL_WIDTH, CELL_HEIGHT, linewidth=1, edgecolor='gray', facecolor=color)\n",
    "                ax.add_patch(rect)\n",
    "        else:\n",
    "            ax.scatter(bricks_data['x'], bricks_data['z'], color='red', label='wire', marker='.')\n",
    "            for index, row in bricks_data.iterrows():\n",
    "                color = cmap(norm(0))\n",
    "                if index in TDC_counts.index:\n",
    "                    color = cmap(norm(TDC_counts.loc[index, 'Counts']))\n",
    "                rect = patches.Rectangle((row['x'] - CELL_WIDTH / 2, row['z'] - CELL_HEIGHT / 2),\n",
    "                                         CELL_WIDTH, CELL_HEIGHT, linewidth=1, edgecolor='gray', facecolor=color)\n",
    "                ax.add_patch(rect)\n",
    "        \n",
    "        ax.set_title(f'Chamber {chamber}')\n",
    "        ax.set_xlabel('x' if chamber != 1 else 'y')\n",
    "        ax.set_ylabel('z')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "        cbar.set_label('Counts')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "def plot_local_fit(df_local_fit, df_hits, n_orbit):\n",
    "    \n",
    "    df_hits = df_hits[df_hits['ORB_CNT']==n_orbit]\n",
    "    df_local_fit = df_local_fit[df_local_fit['ORB_CNT']==n_orbit]\n",
    "    \n",
    "    chambers = df_local_fit['Chamber'].unique()\n",
    "    chambers = chambers[chambers != 1]\n",
    "    chambers_idxs = np.argsort(chambers)[::-1]\n",
    "    chambers = chambers[chambers_idxs]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(chambers), 1, figsize=(12, 10*len(chambers)/3))\n",
    "    fig.suptitle('Local fit plot, ORB_CNT=' + str(n_orbit), fontsize=16)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, chamber in enumerate(chambers):\n",
    "        ax = axes[i]\n",
    "        chamber_data = df_hits[df_hits['Chamber'] == chamber]\n",
    "        bricks_data  = df_bricks[df_bricks['Chamber'] == chamber]\n",
    "\n",
    "        regression_chamber = df_local_fit[df_local_fit['Chamber'] == chamber]\n",
    "        \n",
    "        reg_intercept = regression_chamber['Reg_Intercept'].iloc[0]\n",
    "        reg_coefficient = regression_chamber['Reg_Coefficient'].iloc[0]\n",
    "        x_values = np.linspace(bricks_data['z'].min()-20, bricks_data['z'].max()+20, 100)\n",
    "        y_values = reg_coefficient * x_values + reg_intercept\n",
    "\n",
    "        if chamber == 1:  # using 'y' for scatter plot in chamber 1\n",
    "            ax.scatter(bricks_data['y'], bricks_data['z'], color='red', label='wire', marker='.')\n",
    "            for index, row in bricks_data.iterrows():\n",
    "                rect = patches.Rectangle((row['y'] - CELL_WIDTH/2, row['z'] - CELL_HEIGHT/2), \n",
    "                                         CELL_WIDTH, CELL_HEIGHT, linewidth=1, edgecolor='gray', facecolor='none', alpha=0.5)\n",
    "                ax.add_patch(rect)\n",
    "        else:  # using 'x' for other chambers\n",
    "            ax.scatter(bricks_data['x'], bricks_data['z'], color='red', label='wire', marker='.')\n",
    "            for index, row in bricks_data.iterrows():\n",
    "                rect = patches.Rectangle((row['x'] - CELL_WIDTH/2, row['z'] - CELL_HEIGHT/2), \n",
    "                                         CELL_WIDTH, CELL_HEIGHT, linewidth=1, edgecolor='gray', facecolor='none', alpha=0.9)\n",
    "                ax.add_patch(rect)\n",
    "            \n",
    "        ax.scatter(chamber_data['x_left'], chamber_data['z'], color='blue', label='x_left')\n",
    "        ax.scatter(chamber_data['x_right'], chamber_data['z'], color='orange', label='x_right')\n",
    "        ax.scatter(np.concatenate(regression_chamber['x_values'].values), np.concatenate(regression_chamber['z_values'].values), color='lightgreen', label='choice', marker = 'o')\n",
    "        \n",
    "        ax.plot(y_values, x_values, color='green', label='Fit Line')\n",
    "        ax.set_title(f'Chamber {chamber}')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('z')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#___________________________________________________________________________________________________________________________________\n",
    "\n",
    "def plot_global_fit(df_global_fit, df_hits, n_orbit, df_bricks):\n",
    "    \n",
    "    df_hits = df_hits[df_hits['ORB_CNT']==n_orbit]\n",
    "    df_global_fit = df_global_fit[df_global_fit['ORB_CNT']==n_orbit]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 7.5))\n",
    "    fig.suptitle('Global fit plot, ORB_CNT=' + str(n_orbit), fontsize=16)\n",
    "\n",
    "    chambers = [3, 2, 0]\n",
    "    for ch_idx, chamber in enumerate(chambers):\n",
    "        chamber_data = df_hits[df_hits['Chamber'] == chamber]\n",
    "        bricks_data = df_bricks[df_bricks['Chamber'] == chamber]\n",
    "\n",
    "        for index, row in bricks_data.iterrows():\n",
    "            rect = patches.Rectangle((row['x'] - CELL_WIDTH/2, row['z'] - CELL_HEIGHT/2), \n",
    "                                     CELL_WIDTH, CELL_HEIGHT, linewidth=1, edgecolor='gray', facecolor='none', alpha=0.9)\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        if 'x_left' in chamber_data.columns and 'x_right' in chamber_data.columns:\n",
    "            if ch_idx == 0:\n",
    "                ax.scatter(chamber_data['x_left'], chamber_data['z'], color='blue', label='x_left')\n",
    "                ax.scatter(chamber_data['x_right'], chamber_data['z'], color='orange', label='x_right')\n",
    "            else:\n",
    "                ax.scatter(chamber_data['x_left'], chamber_data['z'], color='blue')\n",
    "                ax.scatter(chamber_data['x_right'], chamber_data['z'], color='orange')\n",
    "        else:\n",
    "            print(f\"Columns 'x_left' or 'x_right' not found in chamber {chamber} data.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "    if not df_global_fit.empty:\n",
    "        global_intercept = df_global_fit['Reg_Intercept'].iloc[0]\n",
    "        global_slope = df_global_fit['Reg_Coefficient'].iloc[0]\n",
    "        \n",
    "        z_values = np.linspace(df_hits['z'].min(), df_hits['z'].max(), 100)\n",
    "        x_values = global_slope * z_values + global_intercept\n",
    "        ax.plot(x_values, z_values, color='green', label='Global Fit Line')\n",
    "\n",
    "        ax.set_title('Global fit')\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('z')\n",
    "    \n",
    "    ax.legend(loc=(0.85, 0.75))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2922f3cc-5e7f-4385-ad72-186bfe133e30",
   "metadata": {},
   "source": [
    "#### Client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e52fd-255d-4369-a67e-c1ec7c603958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 10:25:58,204 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,203 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "2024-09-19 10:25:58,224 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,223 - distributed.scheduler - INFO - State start\n",
      "2024-09-19 10:25:58,225 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-f5y5oet7', purging\n",
      "2024-09-19 10:25:58,225 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-nedomrof', purging\n",
      "2024-09-19 10:25:58,225 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-y_oqfh98', purging\n",
      "2024-09-19 10:25:58,226 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,224 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ovdlm0z2', purging\n",
      "2024-09-19 10:25:58,227 - distributed.deploy.ssh - INFO - 2024-09-19 10:25:58,227 - distributed.scheduler - INFO -   Scheduler at:   tcp://10.67.22.142:8786\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to setup a distributed cluster\n",
    "n_workers = 4\n",
    "nthreads  = 1\n",
    "\n",
    "cluster = SSHCluster(\n",
    "    [\"10.67.22.142\", \"10.67.22.142\", \"10.67.22.209\", \"10.67.22.80\"],\n",
    "    worker_options={\"nthreads\": nthreads, \"n_workers\": n_workers},\n",
    "    scheduler_options={\"port\": 8786, \"dashboard_address\": \":8787\"},\n",
    "    connect_options={\n",
    "        \"known_hosts\": \"/home/coradin/.ssh/known_hosts\",\n",
    "        \"username\": \"coradin\"\n",
    "    },\n",
    "    remote_python=\"/miniconda3/envs/DASK/bin/python\",\n",
    "    \n",
    ")\n",
    "\n",
    "client = Client(cluster, timeout='180s')\n",
    "client.wait_for_workers(n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72fcb1-2c8d-4fbc-98f9-322a95757490",
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07caba4e-732f-4117-be28-359e008af4a1",
   "metadata": {},
   "source": [
    "# Reduced dataset analysis (10 files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a25ad-78a5-44b6-969c-37fa55c34698",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e647229-b144-4dce-80a9-4b690dd75114",
   "metadata": {},
   "source": [
    "### Threshold analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10145adc-edd4-4b42-8012-487ce801b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 's3://project-bkp/data_00000*'\n",
    "\n",
    "df = read_file(filename)\n",
    "df = df.map_partitions(filter_groups_part1)\n",
    "threshold_analysis(MAX_HIT_ORB, MIN_HIT_ORB, df.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b360b8a-55cc-457d-9e73-16511bcd03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_groups_part2_a(df)\n",
    "df_c = df.map_partitions(filter_groups_part2_b).compute()\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49caf6d-f65f-4196-a666-96b094e52f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(13, 7))\n",
    "\n",
    "df0 = df_c[df_c['Chamber'] == 0]\n",
    "df1 = df_c[df_c['Chamber'] == 1]\n",
    "df2 = df_c[df_c['Chamber'] == 2]\n",
    "df3 = df_c[df_c['Chamber'] == 3]\n",
    "\n",
    "bin_number = 100\n",
    "\n",
    "ax[0,0].hist(df0['relative_time'], bins=bin_number, color='lightskyblue', align='mid', edgecolor='royalblue')\n",
    "ax[0,1].hist(df1['relative_time'], bins=bin_number, color='lightskyblue', align='mid', edgecolor='royalblue')\n",
    "ax[1,0].hist(df2['relative_time'], bins=bin_number, color='lightskyblue', align='mid', edgecolor='royalblue')\n",
    "ax[1,1].hist(df3['relative_time'], bins=bin_number, color='lightskyblue', align='mid', edgecolor='royalblue')\n",
    "\n",
    "# Create histograms and calculate the maximum y values (counts)\n",
    "counts0, bins0 = np.histogram(df0['relative_time'], bins=bin_number)\n",
    "counts1, bins1 = np.histogram(df1['relative_time'], bins=bin_number)\n",
    "counts2, bins2 = np.histogram(df2['relative_time'], bins=bin_number)\n",
    "counts3, bins3 = np.histogram(df3['relative_time'], bins=bin_number)\n",
    "\n",
    "# Define the custom quantiles you want to calculate\n",
    "quantile_percentages = [0.01, 0.99]\n",
    "# Calculate the quantiles for the relative_time column\n",
    "quantiles = np.asarray([df0['relative_time'].quantile(quantile_percentages), df1['relative_time'].quantile(quantile_percentages), df2['relative_time'].quantile(quantile_percentages), df3['relative_time'].quantile(quantile_percentages)]).reshape(2,2,2)\n",
    "\n",
    "for k in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        ax[k,j].set_title('Chamber ' + str(k+2*j))\n",
    "        ax[k,j].set_xlabel('Delta t (ns)')\n",
    "        ax[k,j].set_ylabel('Counts')\n",
    "        ax[k,j].set_ylim(0,1.1*max(counts0.max(), counts1.max(), counts2.max(), counts3.max()))\n",
    "        for i, quantile_value in enumerate(quantiles[k,j]):\n",
    "            ax[k,j].axvline(x=quantile_value, color='red', linestyle='--', linewidth=1)\n",
    "            ax[k,j].text(quantile_value-20, ax[k,j].get_ylim()[1] * 0.9, f'{quantile_percentages[i]*100:.0f}%', color='red', rotation=90, verticalalignment='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b557f1c-56b0-42be-a4e0-02cba870ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "orbits_20_counts = df_c.groupby('ORB_CNT').filter(lambda x: len(x) == 20)\n",
    "print(orbits_20_counts['ORB_CNT'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7799093-2be0-49d0-be70-ffb8cc694b82",
   "metadata": {},
   "source": [
    "### Reading and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7e491-44d1-4dee-a7f5-bebd919d977d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 's3://project-bkp/data_00000*'\n",
    "\n",
    "df = read_file(filename)\n",
    "df = df.map_partitions(filter_groups_part1)\n",
    "df = filter_groups_part2_a(df)\n",
    "df = df.map_partitions(filter_groups_part2_b)\n",
    "#df.visualize(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f098e713-fd64-4173-9977-5ca882942655",
   "metadata": {},
   "source": [
    "## Local Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4462ea-3875-445c-b891-398fe9e6adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({\n",
    "    'Chamber_': pd.Series(dtype='int64'),\n",
    "    'ORB_CNT_': pd.Series(dtype='uint64'),\n",
    "    'x_values': pd.Series(dtype='object'),\n",
    "    'z_values': pd.Series(dtype='object'),\n",
    "    'Reg_Coefficient': pd.Series(dtype='float64'),\n",
    "    'Reg_Intercept': pd.Series(dtype='float64'),\n",
    "    'Chi_Squared_NDOF': pd.Series(dtype='float64')\n",
    "})\n",
    "\n",
    "df_regression = df.map_partitions(\n",
    "    lambda partition: (\n",
    "        partition\n",
    "        .groupby(['Chamber', 'ORB_CNT'])\n",
    "        .apply(fit_tracks_vectorized, include_groups=True)\n",
    "    ), \n",
    "    meta=meta).reset_index(drop=True).rename(columns={'Chamber_': 'Chamber', 'ORB_CNT_': 'ORB_CNT'})\n",
    "\n",
    "#df_regression.visualize(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378914fb-339d-485e-893d-625993b08426",
   "metadata": {},
   "source": [
    "## Global fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4a759-5068-4c7b-a698-95bb3fe6f907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({\n",
    "    'ORB_CNT_': pd.Series(dtype='uint64'),\n",
    "    'Reg_Coefficient': pd.Series(dtype='float64'),\n",
    "    'Reg_Intercept':   pd.Series(dtype='float64'),\n",
    "    'Chi_Squared_NDOF': pd.Series(dtype='float64'),\n",
    "    # 'Reg_Coefficient_loc':   pd.Series(dtype='float64')\n",
    "})\n",
    "\n",
    "global_tracks_df = df_regression.map_partitions(\n",
    "    lambda partition: (\n",
    "        partition\n",
    "        .groupby(['ORB_CNT'])\n",
    "        .apply(fit_global_tracks, include_groups=True)   \n",
    "    ), \n",
    "    meta=meta).dropna().reset_index(drop=True).rename(columns={'ORB_CNT_': 'ORB_CNT'})\n",
    "\n",
    "#global_tracks_df.visualize(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56c676-6215-4748-af7c-8bfe409d03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "global_fit_df = global_tracks_df.compute()\n",
    "\n",
    "global_fit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8415f-8958-43ad-a520-3b1152573857",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbe26a-76b5-4353-a731-cb149e6de806",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_res = df.compute()\n",
    "n_orbit = 8333222   \n",
    "\n",
    "df_res[df_res['ORB_CNT'] == n_orbit]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acad0b9-0f44-453b-b7e8-73b487f10ed7",
   "metadata": {},
   "source": [
    "### Hit counts per channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73786aa-5685-4eac-a89a-05e7a7030e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chambers = [3, 2, 1, 0]\n",
    "\n",
    "plot_hit_counts(chambers, df_res, df_bricks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baddaf4a-f93a-40f3-bf8f-230d26a38e30",
   "metadata": {},
   "source": [
    "### Local fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9e212-0b35-4664-8d43-46e1267c6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "regression_results_df = df_regression.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815f42e-6fa5-4597-921f-47a940149462",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_fit(regression_results_df, df_res, n_orbit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8107ea-ce05-4383-9ca1-c22bfac4f9c0",
   "metadata": {},
   "source": [
    "### Global fit plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e771cbd-dcd8-4668-943a-96ea67c65617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_global_fit(global_fit_df, df_res, n_orbit, df_bricks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d984bea-12a7-4208-be2e-43580ceae579",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(global_fit_df[global_fit_df['Chi_Squared_NDOF'] < 5]['Chi_Squared_NDOF'], bins=100, density=False)\n",
    "plt.xlabel('Chi_Squared/NDOF')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Chi squared of the global fits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f41db4-19ca-4df5-9f3c-4b69be6a1a62",
   "metadata": {},
   "source": [
    "# Whole dataset analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92fb73a-f439-47d2-8017-8188e0bbd249",
   "metadata": {},
   "source": [
    "## Preprocessing, local and global fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb70fe2-b7f3-4dd8-9922-70492524f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_all = 's3://project-bkp/data_0000*'\n",
    "\n",
    "df_all = read_file(filename_all)\n",
    "df_all = df_all.repartition(npartitions=n_partitions)\n",
    "df_all = df_all.map_partitions(filter_groups_part1)\n",
    "df_all = filter_groups_part2_a(df_all)\n",
    "df_all = df_all.map_partitions(filter_groups_part2_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38920c-88f1-48b7-b86b-a83c5ada335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({\n",
    "    'Chamber_': pd.Series(dtype='int64'),\n",
    "    'ORB_CNT_': pd.Series(dtype='uint64'),\n",
    "    'x_values': pd.Series(dtype='object'),\n",
    "    'z_values': pd.Series(dtype='object'),\n",
    "    'Reg_Coefficient': pd.Series(dtype='float64'),\n",
    "    'Reg_Intercept': pd.Series(dtype='float64'),\n",
    "    'Chi_Squared_NDOF': pd.Series(dtype='float64')\n",
    "})\n",
    "\n",
    "df_regression_all = df_all.map_partitions(\n",
    "    lambda partition: (\n",
    "        partition\n",
    "        .groupby(['Chamber', 'ORB_CNT'])\n",
    "        .apply(fit_tracks_vectorized, include_groups=True)  # Use the vectorized version here\n",
    "    ), \n",
    "    meta=meta).reset_index(drop=True).rename(columns={'Chamber_': 'Chamber', 'ORB_CNT_': 'ORB_CNT'})\n",
    "\n",
    "#df_regression_all.visualize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c6fd3-0750-4352-8c0d-30034faeb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.DataFrame({\n",
    "    'ORB_CNT_': pd.Series(dtype='uint64'),\n",
    "    'Reg_Coefficient': pd.Series(dtype='float64'),\n",
    "    'Reg_Intercept':   pd.Series(dtype='float64'),\n",
    "    'Chi_Squared_NDOF': pd.Series(dtype='float64')\n",
    "})\n",
    "\n",
    "global_tracks_df_all = df_regression_all.map_partitions(\n",
    "    lambda partition: (\n",
    "        partition\n",
    "        .groupby(['ORB_CNT'])\n",
    "        .apply(fit_global_tracks, include_groups=True)   \n",
    "    ), \n",
    "    meta=meta).dropna().reset_index(drop=True).rename(columns={'ORB_CNT_': 'ORB_CNT'}).repartition(npartitions=1)\n",
    "\n",
    "#global_tracks_df_all.visualize(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7668d7f9-30ff-4168-8580-70653fb24627",
   "metadata": {},
   "source": [
    "## Angular difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1af92b-70bb-406d-833b-5f5c2f796ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_fit_df_rn_all = global_tracks_df_all[global_tracks_df_all['Chi_Squared_NDOF'] < .7].rename(columns={'Reg_Coefficient':'Reg_Coefficient_glo', 'Reg_Intercept':'Reg_Intercept_glo'})\n",
    "regression_results_df_ch2_rn_all = df_regression_all.rename(columns={'Chamber_':'Chamber', 'ORB_CNT_':'ORB_CNT', 'Reg_Coefficient':'Reg_Coefficient_loc', 'Reg_Intercept':'Reg_Intercept_loc'}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889e343-478b-4603-97af-92f7a49a6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ang_diff_all = global_fit_df_rn_all.merge(regression_results_df_ch2_rn_all, on = ['ORB_CNT'])\n",
    "\n",
    "df_ang_diff_all['Angular difference'] = (np.arctan(df_ang_diff_all['Reg_Coefficient_glo']) - np.arctan(df_ang_diff_all['Reg_Coefficient_loc']))*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58337f0a-7847-40fb-b1d9-1d6067eda843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ang_diff_all.visualize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa3099-f5a6-4113-87d5-74377e70d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_ang_diff_all_computed = df_ang_diff_all.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1c87d-fb9e-48bc-a906-cf3c2a3379ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(12, 4))\n",
    "axs[0].hist(df_ang_diff_all_computed['Angular difference'], bins=500)\n",
    "axs[0].set_xlabel('Angular difference (deg)')\n",
    "axs[0].set_ylabel('Counts')\n",
    "\n",
    "mask_zoom = (df_ang_diff_all_computed['Angular difference'] > -3) & (df_ang_diff_all_computed['Angular difference'] < 3)\n",
    "\n",
    "axs[1].hist(df_ang_diff_all_computed[mask_zoom]['Angular difference'], bins=100, density=True)\n",
    "axs[1].set_xlabel('Angular difference (deg)')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98114d58-63f8-4455-a6d9-a608c0ee7c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ang_diff_all_computed[mask_zoom]['Angular difference'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92509524-bf1b-46f5-91c3-6c5b8da0b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ang_diff_all_computed[mask_zoom]['Angular difference'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236307e-ffe3-41ff-994a-8815576a2f0d",
   "metadata": {},
   "source": [
    "## Stopping the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90d60e6-0f09-4398-bc84-73bed20da7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b292b09-a533-4394-9044-916ac8bc861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_min = int((end - start)/60)\n",
    "tot_sec = (end - start) - 60*int((end - start)/60)\n",
    "print(f'Total time: {tot_min:.0f} min {tot_sec:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabd62a-77c4-48c9-8cb2-5cd8487fb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
